{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d9ca9a0",
   "metadata": {},
   "source": [
    "# Train YOLO Model with Custom Data and Export to NCNN\n",
    "This notebook demonstrates how to train a YOLO model with your own images and labels, export the trained model to NCNN format, and test the exported model on a custom image for object detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea3cae",
   "metadata": {},
   "source": [
    "## 0. How to Get Open Source Images and Label Them for Custom Training\n",
    "\n",
    "### 1. Downloading Open Source Images\n",
    "- Use public datasets from sources like [Roboflow Universe](https://universe.roboflow.com/), [Kaggle Datasets](https://www.kaggle.com/datasets), [Open Images Dataset](https://storage.googleapis.com/openimages/web/index.html), or [Google Dataset Search](https://datasetsearch.research.google.com/).\n",
    "- For manufacturer labels, search for datasets with product images, packaging, or industrial scenes. If no dataset exists, you can use Google Images or Bing Images to download images (ensure you have the right to use them).\n",
    "- Tools like [OpenCV's image downloader](https://github.com/hardikvasa/google-images-download) or [icrawler](https://github.com/hellock/icrawler) can automate image collection.\n",
    "\n",
    "### 2. Labeling Images\n",
    "- Use annotation tools such as [LabelImg](https://github.com/tzutalin/labelImg), [Roboflow Annotate](https://roboflow.com/annotate), or [CVAT](https://github.com/opencv/cvat) to draw bounding boxes around manufacturer labels or items of interest.\n",
    "- Save annotations in YOLO format (one `.txt` file per image, with class and bounding box coordinates).\n",
    "\n",
    "### 3. Creating a Custom Dataset\n",
    "- Organize your dataset as described in Section 2 of this notebook: separate `images/train`, `images/val`, `labels/train`, and `labels/val` folders, and create a `data.yaml` file listing class names.\n",
    "\n",
    "**Tip:** Roboflow can help you convert and export datasets directly in YOLO format, ready for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d24a3",
   "metadata": {},
   "source": [
    "## 1. Install Required Libraries\n",
    "Install the necessary libraries for YOLO training and NCNN export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca841e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install YOLOv5, PyTorch, and NCNN export dependencies\n",
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install opencv-python\n",
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "%cd yolov5\n",
    "!pip install -r requirements.txt\n",
    "# Install onnx and onnxsim for export\n",
    "!pip install onnx onnxsim\n",
    "# Install ncnn2mem for NCNN conversion (requires build from source or prebuilt binary)\n",
    "# See: https://github.com/nihui/ncnn2mem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994204de",
   "metadata": {},
   "source": [
    "## 2. Prepare Custom Dataset\n",
    "Organize your images and labels in YOLO format and create a data.yaml file describing your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f67d59",
   "metadata": {},
   "source": [
    "Your dataset directory should look like this:\n",
    "\n",
    "```\n",
    "custom_dataset/\n",
    "├── images/\n",
    "│   ├── train/\n",
    "│   └── val/\n",
    "├── labels/\n",
    "│   ├── train/\n",
    "│   └── val/\n",
    "└── data.yaml\n",
    "```\n",
    "\n",
    "Example `data.yaml`:\n",
    "```\n",
    "train: /content/custom_dataset/images/train\n",
    "val: /content/custom_dataset/images/val\n",
    "nc: 2  # number of classes\n",
    "names: ['class1', 'class2']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a83a84",
   "metadata": {},
   "source": [
    "## 3. Train YOLOv5 Model with Custom Data\n",
    "Train the YOLOv5 model using your custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f80151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train YOLOv5 model with custom data\n",
    "# Update the path to your data.yaml file\n",
    "custom_data_yaml = '/content/custom_dataset/data.yaml'  # Update this path\n",
    "output_dir = 'runs/train/custom_yolo_model'   # Directory to save trained model\n",
    "\n",
    "!python train.py --img 640 --batch 16 --epochs 50 --data $custom_data_yaml --weights yolov5s.pt --project runs/train --name custom_yolo_model\n",
    "\n",
    "# The best model will be saved in output_dir/weights/best.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5a07e8",
   "metadata": {},
   "source": [
    "## 4. Export Trained Model to NCNN Format\n",
    "Export the trained YOLOv5 model to ONNX, then convert ONNX to NCNN format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export trained YOLOv5 model to ONNX\n",
    "best_weights = 'runs/train/custom_yolo_model/weights/best.pt'  # Update if needed\n",
    "onnx_output = 'best.onnx'\n",
    "\n",
    "!python export.py --weights $best_weights --img 640 --batch 1 --include onnx\n",
    "\n",
    "# Convert ONNX to NCNN (requires ncnn and ncnn2mem tool)\n",
    "# Download ncnn tools from https://github.com/Tencent/ncnn/releases or build from source\n",
    "# Example command (run in shell, not Python):\n",
    "# !./onnx2ncnn best.onnx best.param best.bin\n",
    "# !./ncnn2mem best.param best.bin best.id.h best.id.c\n",
    "\n",
    "print('ONNX export complete. Use ncnn tools to convert to NCNN format.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f346e088",
   "metadata": {},
   "source": [
    "## 5. Load Trained NCNN Model and Test on Custom Image\n",
    "Use the NCNN C++/Python API to load the exported model and run inference on a custom image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and test NCNN model (Python API example, if available)\n",
    "# Note: Official NCNN Python API is limited; most use C++ for inference.\n",
    "# Below is a placeholder for Python. For C++, use the ncnn examples from https://github.com/Tencent/ncnn\n",
    "\n",
    "# If you have ncnn Python bindings installed:\n",
    "# import ncnn\n",
    "# net = ncnn.Net()\n",
    "# net.load_param('best.param')\n",
    "# net.load_model('best.bin')\n",
    "# img = cv2.imread('/path/to/custom_image.jpg')\n",
    "# ... (preprocess and run inference)\n",
    "\n",
    "print('For NCNN inference, use the C++ API or ncnn Python bindings if available. See ncnn documentation for details.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
